{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook preprocessed the master class data \n",
    "Note: All of the following functions have been added to utils. Please update utils if any further changes are made in this file <br>\n",
    "- Found and map quantitative data which somehow were not been labeled correctly  (The mapping dictionary is still constructing...)\n",
    "- Use pre-trained Free Response Cluster classifier to label the Non-Quantitative FR variables\n",
    "- Bin the Grades into quantiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "DMOL_DIR = \"/Users/Henryye/research/shaf/DMOL\"\n",
    "sys.path.append(os.path.join(DMOL_DIR, \"utils\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "from ml_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_no_map_cap = {\"Yes\": 1, \"No\": 0, \"nan\": np.nan}\n",
    "yes_no_map_lower = {\"yes\": 1, \"no\": 0, \"nan\": np.nan}\n",
    "begscl_map = {'I always received my schooling in English': 1, 'age 2-4': 2, 'age 5-7': 3, \n",
    "              'age 8-10': 4, 'age 11-13': 5, 'age 14-17': 6, 'age 18-21': 7,'after age 21': 8, \"nan\": np.nan}\n",
    "parents_map = {'No': 1, 'Yes, one parent': 2, \"Yes, both parents\": 3, 'nan': np.nan}\n",
    "resid_map = {\"On-campus\": 1, \"Off-campus, but less than one hour away\": 2, \"Off-campus, and more than one hour away\": 3, \"nan\": np.nan}\n",
    "courses_map = {'0': 1, '1': 2, '2': 3, '3+':4, \"4\": np.nan, 'nan': np.nan}\n",
    "courses_imp_map = {\"Most important\": 4, \"Second-most important\": 3, \"Third-most important\": 2, \"Fourth-most important\": 1, \"nan\": np.nan}\n",
    "courses_int_map = {\"Most interesting\": 4, \"Second-most interesting\": 3, \"Third-most interesting\": 2, \"Fourth-most interesting\": 1, \"nan\": np.nan}\n",
    "aca_map = {'Every week': 6, 'Never': 1, 'Once a month': 4, 'Once a quarter':2, 'Twice a month':3, 'Twice a quarter':5 , \"nan\": np.nan}\n",
    "sp_map = { 'Neither agree nor disagree':3, 'Strongly agree':5, 'Strongly disagree':1, '4': 4, '2':2, \"nan\": np.nan}\n",
    "canv_map = {'Important':4, 'Somewhat unimportant':3, 'Unimportant':2, 'Very important':5, 'Very unimportant': 1, \"nan\": np.nan}\n",
    "studyplan_chg_map = {'I never had a study plan': 1, 'No, I stuck to my plan': 0, \n",
    "                     'Yes, I changed my study plan a bit':2, 'Yes, I changed my study plan a lot':3,'nan': np.nan}\n",
    "sex_map = {'Female': 0, 'Male': 1, 'nan': np.nan}\n",
    "perfown_map = {'About the same':1, 'Better':2, \"I don't know\":4, 'Worse':3, 'nan':np.nan}\n",
    "perforce_map = {'I am about the same as other students':2,\n",
    " 'I am less smart than other students':3, 'I am smarter than other students':1,\n",
    " \"Others won't have a way of judging whether I am smart in my class\":4, 'nan':np.nan}\n",
    "grade_scale_map = {'A+': 13, 'A': 12, 'A-': 11, 'B+': 10, 'B': 9, 'B-': 8, 'C+': 7, 'C': 6, \n",
    "                   'C-': 5, 'D+': 4, 'D': 3, 'D-': 2, 'F': 1, 'NA': np.nan, \"nan\": np.nan}\n",
    "\n",
    "act_cluster_label_map = {\n",
    "    'oact': {0: 'General', 1: 'Work', 2: 'Another Course', 3: 'Personal'},\n",
    "    'cact': {}\n",
    "}\n",
    "\n",
    "COL_MAP_LIST = [yes_no_map_cap, yes_no_map_lower,begscl_map, parents_map, resid_map, courses_map, courses_imp_map, \n",
    "           courses_int_map, aca_map, sp_map, canv_map, studyplan_chg_map, sex_map, perfown_map, perforce_map, grade_scale_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_vars = lambda key: [j for v in VAR_MAP[key].values() for j in list(v)]\n",
    "\n",
    "def separate_quant_fr(var_map):\n",
    "    new_var_map = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))\n",
    "    for key in var_map:\n",
    "        data_types = df[grab_vars(key)].dtypes\n",
    "        for construct in VAR_MAP[key]:\n",
    "            for var in VAR_MAP[key][construct]:\n",
    "                if data_types[var] == np.dtype('float64'):\n",
    "                    new_var_map[key][\"Quant\"][construct].add(var)\n",
    "                else:\n",
    "                    new_var_map[key][\"FR\"][construct].add(var)\n",
    "    reformated_all_var = [var for k in new_var_map for t in [\"Quant\", \"FR\"] for var_list in new_var_map[k][t].values() for var in var_list ]\n",
    "    assert(set(ALL_VAR) == set(reformated_all_var))\n",
    "    return new_var_map\n",
    "\n",
    "def convert_fr_col(df, num_uniq = 10, verbose = True):\n",
    "    \n",
    "    def map_column(df, v):\n",
    "        mapped, col_type = False, \"str\"\n",
    "        try:\n",
    "            uniq_val, col_type = np.unique(df[v].astype('float64')).tolist(), \"float\"\n",
    "        except:\n",
    "            uniq_val = np.unique(df[v].astype('str')).tolist()\n",
    "            \n",
    "        for col_map in COL_MAP_LIST:\n",
    "            if len(set(uniq_val).intersection(set(col_map.keys()))) == len(uniq_val):\n",
    "                df[v] = df[v].map(col_map)\n",
    "                mapped = True\n",
    "                break\n",
    "                \n",
    "        if not mapped and verbose:\n",
    "            print(\"Cannot find map for variable {}(type = {}), uniq vals are {}\".format(v, col_type, uniq_val))\n",
    "        return df\n",
    "        \n",
    "    for v in ALL_NON_QUANT_VAR:\n",
    "        if df[ALL_NON_QUANT_VAR].nunique()[v] < num_uniq:\n",
    "            df = map_column(df, v)\n",
    "        elif verbose:\n",
    "            print(\"Var {} has more than {} unique vals\".format(v, num_uniq))\n",
    "    return df\n",
    "\n",
    "def get_fr_cluster_label(df):\n",
    "    \n",
    "    def label_activity(df, cluster_pkl, act_type):\n",
    "        vectorizer, classifier = cluster_pkl[act_type]\n",
    "        col_names = [c for c in df.columns if \"oact\" in c and \"compx\" not in c] if act_type == \"oact\" else \\\n",
    "                    [\"dcact{}\".format(i) for i in range(1, 31)] if act_type == \"cact\" else None\n",
    "        col_names = list(set(col_names).intersection(ALL_NON_QUANT_VAR))\n",
    "        for col in col_names:\n",
    "            act_data = [nlp_preprocess(act, use_stemmer=True) for act in df[col].fillna('').tolist()]\n",
    "            df[col] = classifier.predict(vectorizer.transform(act_data)).tolist()\n",
    "        return df\n",
    "    \n",
    "    cluster_pkl = load_object(\"../data/act_list_cluster.pkl\")\n",
    "    for act_type in [\"oact\", 'cact']:\n",
    "        df = label_activity(df, cluster_pkl, act_type)\n",
    "    return df\n",
    "\n",
    "def encode_target_vars(df):\n",
    "    target_vars = [\"gr_revq1\", \"gr_revq2\", \"gr_revq3\", \"gr_revq4\", \"gr_revq5\", \"gr_exam1\", \"gr_exam2\", \"gr_exam3\"]\n",
    "    all_target_vars = []\n",
    "    for var in target_vars:\n",
    "        quantile_encodings = []\n",
    "        df[var] = df[var].fillna(0)\n",
    "        \n",
    "        bot = np.quantile(df[var], .25)\n",
    "        med = np.quantile(df[var], .50)\n",
    "        top = np.quantile(df[var], .75)\n",
    "        \n",
    "        for val in df[var]:\n",
    "            if val <= bot:\n",
    "                quantile_encodings.append(1)\n",
    "            elif val > bot and val <= med:\n",
    "                quantile_encodings.append(2)\n",
    "            elif val > med and val <= top:\n",
    "                quantile_encodings.append(3)\n",
    "            else:\n",
    "                quantile_encodings.append(4)\n",
    "                \n",
    "        df[var + \"_quantile\"] = quantile_encodings\n",
    "        all_target_vars.append(var)\n",
    "        all_target_vars.append(var + \"_quantile\")\n",
    "    return df\n",
    "\n",
    "def preprocess_df(df, verbose = True):\n",
    "    proc_df = df[df[\"pre_studyinterest\"] == \"Yes\"].reset_index(drop = True).copy()\n",
    "    proc_df = encode_target_vars(proc_df)\n",
    "    proc_df = convert_fr_col(proc_df, verbose = verbose)\n",
    "    proc_df = get_fr_cluster_label(proc_df)\n",
    "    return proc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/class_data.csv\")\n",
    "VAR_MAP = load_object(\"../data/var_map.pkl\")\n",
    "\n",
    "NEW_VAR_MAP = separate_quant_fr(VAR_MAP)\n",
    "ALL_VAR = [var for k in VAR_MAP for var_list in VAR_MAP[k].values() for var in var_list]\n",
    "ALL_QUANT_VAR = [var for k in NEW_VAR_MAP for var_list in NEW_VAR_MAP[k][\"Quant\"].values() for var in var_list]\n",
    "ALL_NON_QUANT_VAR = [var for k in NEW_VAR_MAP for var_list in NEW_VAR_MAP[k][\"FR\"].values() for var in var_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot find map for variable pre_distribution(type = str), uniq vals are ['anonymous', 'email']\n",
      "Cannot find map for variable post_distribution(type = str), uniq vals are ['email', 'nan']\n"
     ]
    }
   ],
   "source": [
    "proc_df = preprocess_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
